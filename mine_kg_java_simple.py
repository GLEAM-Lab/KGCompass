#!/usr/bin/env python3
"""
ç®€å•çš„ Java KG æŒ–æ˜è„šæœ¬ï¼Œç›´æ¥ä» swe-bench_java ç›®å½•è¯»å– JSONL æ–‡ä»¶
"""

import argparse
import json
import subprocess
import os
from pathlib import Path
import glob

# Java ä»“åº“ URL æ˜ å°„
JAVA_REPO_URL_MAP = {
    "google__gson": "https://github.com/google/gson.git",
    "fasterxml__jackson-databind": "https://github.com/FasterXML/jackson-databind.git",
    "fasterxml__jackson-core": "https://github.com/FasterXML/jackson-core.git",
    "fasterxml__jackson-dataformat-xml": "https://github.com/FasterXML/jackson-dataformat-xml.git",
    "mockito__mockito": "https://github.com/mockito/mockito.git",
    "apache__dubbo": "https://github.com/apache/dubbo.git",
    "elastic__logstash": "https://github.com/elastic/logstash.git",
    "alibaba__fastjson2": "https://github.com/alibaba/fastjson2.git",
    "googlecontainertools__jib": "https://github.com/GoogleContainerTools/jib.git",
}

def set_proxy_env():
    """è®¾ç½®ä»£ç†ç¯å¢ƒå˜é‡"""
    os.environ['http_proxy'] = 'http://172.27.16.1:7890'
    os.environ['https_proxy'] = 'http://172.27.16.1:7890'
    print("ä»£ç†å·²è®¾ç½®: http://172.27.16.1:7890")

def run_cmd(cmd: list):
    print(f"$ {' '.join(cmd)}")
    subprocess.run(cmd, check=True)

def process_instance(instance_data: dict, repos_dir: Path, output_root: Path, idx: int, total: int):
    instance_id = instance_data.get('instance_id')
    if not instance_id:
        print(f"âŒ ç¼ºå°‘ instance_idï¼Œè·³è¿‡")
        return

    # ä» org/repo æ„å»º repo_identifier
    org = instance_data.get('org', '')
    repo = instance_data.get('repo', '')
    repo_identifier = f"{org}__{repo}"

    kg_output_dir = output_root / repo_identifier
    kg_output_dir.mkdir(parents=True, exist_ok=True)
    result_file = kg_output_dir / f"{instance_id}.json"
    
    if result_file.exists():
        print(f"[{idx}/{total}] âœ… KG exists for {instance_id}, skipping.")
        return

    clone_url = JAVA_REPO_URL_MAP.get(repo_identifier)
    if not clone_url:
        print(f"âŒ Repo identifier {repo_identifier} not found in mapping, skipping {instance_id}.")
        return

    repo_path = repos_dir / repo_identifier
    if not repo_path.exists():
        print(f"[{idx}/{total}] ğŸŒ€ Cloning {repo_identifier} â€¦ (full history, this may take a while)")
        run_cmd(["git", "clone", clone_url, str(repo_path)])
    else:
        print(f"[{idx}/{total}] âœ… Repo exists, skip clone.")

    # ç¡®ä¿ç›®æ ‡æäº¤å­˜åœ¨ï¼šè·å–æœ€æ–°è¿œç¨‹å†å²ï¼ˆå¦‚æœä¹‹å‰å·²æµ…å…‹éš†ï¼Œæ­¤æ­¥éª¤ä¼šè¡¥å…¨ç¼ºå¤±æäº¤ï¼‰
    run_cmd(["git", "-C", str(repo_path), "fetch", "--all", "--tags"])

    # æ‰§è¡Œ KG æŒ–æ˜ï¼Œä½¿ç”¨ multi-swe-bench åŸºå‡†
    print(f"[{idx}/{total}] ğŸš€ Mining KG for {instance_id} â€¦")
    run_cmd(["python3", "kgcompass/fl.py", instance_id, repo_identifier, str(kg_output_dir), "multi-swe-bench"])
    print(f"[{idx}/{total}] ğŸ‰ Saved to {result_file}\n")

def load_java_datasets(data_dir: Path):
    """ä» swe-bench_java ç›®å½•åŠ è½½æ‰€æœ‰ JSONL æ–‡ä»¶"""
    print(f"ä» {data_dir} ç›®å½•åŠ è½½ Java æ•°æ®é›†...")
    
    # æŸ¥æ‰¾æ‰€æœ‰ JSONL æ–‡ä»¶
    jsonl_files = list(data_dir.glob("*_dataset.jsonl"))
    if not jsonl_files:
        print(f"âŒ åœ¨ {data_dir} ç›®å½•ä¸­æ²¡æœ‰æ‰¾åˆ° *_dataset.jsonl æ–‡ä»¶")
        return []
    
    all_instances = []
    for jsonl_file in jsonl_files:
        print(f"æ­£åœ¨åŠ è½½: {jsonl_file.name}")
        try:
            with open(jsonl_file, 'r', encoding='utf-8') as f:
                for line_num, line in enumerate(f, 1):
                    try:
                        data = json.loads(line.strip())
                        # ç”Ÿæˆ instance_idï¼ˆå¦‚æœæ²¡æœ‰çš„è¯ï¼‰
                        if 'instance_id' not in data:
                            org = data.get('org', '')
                            repo = data.get('repo', '')
                            number = data.get('number', '')
                            data['instance_id'] = f"{org}__{repo}-{number}"
                        all_instances.append(data)
                    except json.JSONDecodeError as e:
                        print(f"âš ï¸  {jsonl_file.name} ç¬¬ {line_num} è¡Œ JSON è§£æé”™è¯¯: {e}")
                        continue
        except Exception as e:
            print(f"âŒ è¯»å–æ–‡ä»¶ {jsonl_file} å¤±è´¥: {e}")
            continue
    
    print(f"æ€»å…±åŠ è½½äº† {len(all_instances)} ä¸ª Java å®ä¾‹")
    return all_instances

def main():
    parser = argparse.ArgumentParser(description="ç®€å•çš„ Java KG æŒ–æ˜è„šæœ¬")
    parser.add_argument("--output", default="java_kg_results", help="è¾“å‡ºç›®å½•")
    parser.add_argument("--repos_dir", default="playground", help="ä»“åº“å…‹éš†ç›®å½•")
    parser.add_argument("--limit", type=int, default=None, help="é™åˆ¶å¤„ç†å®ä¾‹æ•°é‡ï¼ˆè°ƒè¯•ç”¨ï¼‰")
    parser.add_argument("--start", type=int, default=0, help="å¼€å§‹ç´¢å¼•")
    parser.add_argument("--data_file", default=None, help="æŒ‡å®šå•ä¸ª JSONL æ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼‰")
    args = parser.parse_args()

    # è®¾ç½®ä»£ç†
    set_proxy_env()

    os.environ.setdefault("PYTHONPATH", os.getcwd())

    output_root = Path(args.output)
    output_root.mkdir(parents=True, exist_ok=True)
    repos_dir = Path(args.repos_dir)
    repos_dir.mkdir(parents=True, exist_ok=True)

    # åŠ è½½æ•°æ®
    if args.data_file:
        # ä»æŒ‡å®šæ–‡ä»¶åŠ è½½
        print(f"ä»æŒ‡å®šæ–‡ä»¶åŠ è½½: {args.data_file}")
        all_instances = []
        with open(args.data_file, 'r', encoding='utf-8') as f:
            for line_num, line in enumerate(f, 1):
                try:
                    data = json.loads(line.strip())
                    if 'instance_id' not in data:
                        org = data.get('org', '')
                        repo = data.get('repo', '')
                        number = data.get('number', '')
                        data['instance_id'] = f"{org}__{repo}-{number}"
                    all_instances.append(data)
                except json.JSONDecodeError as e:
                    print(f"âš ï¸  ç¬¬ {line_num} è¡Œ JSON è§£æé”™è¯¯: {e}")
                    continue
    else:
        # ä» swe-bench_java ç›®å½•åŠ è½½æ‰€æœ‰æ–‡ä»¶
        data_dir = Path("swe-bench_java")
        if not data_dir.exists():
            print(f"âŒ æ•°æ®ç›®å½• {data_dir} ä¸å­˜åœ¨")
            return
        all_instances = load_java_datasets(data_dir)

    if not all_instances:
        print("âŒ æ²¡æœ‰æ‰¾åˆ°ä»»ä½•å®ä¾‹")
        return

    # åº”ç”¨èŒƒå›´é™åˆ¶
    start_idx = args.start
    end_idx = len(all_instances)
    if args.limit:
        end_idx = min(start_idx + args.limit, len(all_instances))
    
    instances_to_process = all_instances[start_idx:end_idx]
    total = len(instances_to_process)
    
    print(f"å°†å¤„ç† {total} ä¸ªå®ä¾‹ (ç´¢å¼• {start_idx}-{end_idx-1})")

    # å¤„ç†å®ä¾‹
    for idx, instance_data in enumerate(instances_to_process, start=1):
        try:
            process_instance(instance_data, repos_dir, output_root, idx, total)
        except Exception as e:
            instance_id = instance_data.get('instance_id', 'unknown')
            print(f"âŒ å¤„ç†å®ä¾‹ {instance_id} æ—¶å‡ºé”™: {e}")
            continue

    print("===========================================")
    print("ğŸ‰ æ‰€æœ‰å®ä¾‹å¤„ç†å®Œæˆ")
    print(f"KG JSON æ–‡ä»¶ä¿å­˜åœ¨ {output_root}")
    print("===========================================")

if __name__ == "__main__":
    main() 