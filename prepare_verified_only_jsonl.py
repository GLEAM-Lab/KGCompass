#!/usr/bin/env python3
"""
ç”Ÿæˆåªåœ¨ SWE-bench Verified ä¸­å‡ºçŽ°ä½†ä¸åœ¨ SWE-bench Lite ä¸­å‡ºçŽ°çš„å®žä¾‹åˆ—è¡¨
"""

import json
from datasets import load_dataset

OUTPUT_PATH = "SWE-bench_Verified_only_ids.jsonl"

def main():
    print("ðŸ“¦ Loading SWE-bench datasets from HuggingFace...")
    
    # åŠ è½½ä¸¤ä¸ªæ•°æ®é›†
    print("Loading SWE-bench Verified...")
    verified_ds = load_dataset("princeton-nlp/SWE-bench_Verified", split="test")
    
    print("Loading SWE-bench Lite...")
    lite_ds = load_dataset("princeton-nlp/SWE-bench_Lite", split="test")
    
    # æå– instance_id
    verified_ids = {sample["instance_id"] for sample in verified_ds}
    lite_ids = {sample["instance_id"] for sample in lite_ds}
    
    print(f"SWE-bench Verified: {len(verified_ids)} instances")
    print(f"SWE-bench Lite: {len(lite_ids)} instances")
    
    # è®¡ç®—å·®é›†ï¼šåªåœ¨ Verified ä¸­å‡ºçŽ°ã€ä½†ä¸åœ¨ Lite ä¸­å‡ºçŽ°çš„åˆ—è¡¨
    only_verified_ids = sorted(verified_ids - lite_ids)
    
    print(f"Only in Verified (not in Lite): {len(only_verified_ids)} instances")
    
    # ä¿å­˜ä¸º JSONL æ ¼å¼
    with open(OUTPUT_PATH, "w") as f:
        for instance_id in only_verified_ids:
            f.write(json.dumps({"instance_id": instance_id}, ensure_ascii=False) + "\n")
    
    print(f"âœ… Written {len(only_verified_ids)} instances to {OUTPUT_PATH}")
    
    # æ˜¾ç¤ºå‰10ä¸ªç¤ºä¾‹
    print(f"\nå‰10ä¸ªç¤ºä¾‹:")
    for i, instance_id in enumerate(only_verified_ids[:10]):
        print(f"  {i+1}. {instance_id}")
    
    if len(only_verified_ids) > 10:
        print(f"  ... è¿˜æœ‰ {len(only_verified_ids) - 10} ä¸ªå®žä¾‹")

if __name__ == "__main__":
    main() 